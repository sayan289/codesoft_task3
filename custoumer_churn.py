# -*- coding: utf-8 -*-
"""Custoumer_Churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UmKkOHSrCfQu5n05kSsTJO5VDeenjpgU

### IMPORTING ALL THE MODULES
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.datasets import load_digits
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import RandomOverSampler

"""### READING THE DATASET FROM DIRECTORY"""

df=pd.read_csv(r'D:\Codsoft\Churn_Modelling.csv')

"""### DATA PREPROCESSING PORTION"""

df.head(5)

df.tail()

df.describe()

df.columns

df.dtypes

df['Surname']

df.isnull().sum()

df=df.drop(['Surname', 'RowNumber','CustomerId'], axis=1)

df.dtypes

df.head()

df['Gender'].unique()

df['Gender1']=np.where(df['Gender']=='Male',0,1)

df['Geography'].unique()

df['Geography1']=np.where(df['Geography']=='France',0,np.where(df['Geography']=='Spain',1,2))

df.head()

df1=df[['CreditScore','Geography1','Gender1','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','Exited']]

df1.head()

df1.Exited.value_counts()

"""### CHECKING THE DATASET IS BALANCED OR NOT"""

#NOEW LETS CHECK WHETHER THE OUTCOME COLUMN IS BALANCED
color_wheel = {1: "#0392cf", 2: "#7bc043"}
colors = df1["Exited"].map(lambda x: color_wheel.get(x + 1))
print(df1.Exited.value_counts())
p=df1.Exited.value_counts().plot(kind="bar")

"""#### FROM THE ABOVE DATASET WE CAN SEE THE DATASET IS TOTALLY UNBALANCED"""

x=df1.iloc[:,0:10]

x[:5]

y=df1.iloc[:,10]

y[:5]

x.shape

y.shape

"""### BALANCING THE DATASET"""

pip install -U imbalanced-learn

ros = RandomOverSampler(random_state=42)

x_ros, y_ros = ros.fit_resample(x, y)

print('Original dataset shape', df1.Exited.value_counts())
print('Resample dataset shape', np.unique(y_ros, return_counts=True))

x=x_ros
y=y_ros

"""### PLOTING THE DATASET AFTER BALANCING"""

color_wheel = {1: "#0392cf", 2: "#7bc043"}
colors = y.map(lambda x: color_wheel.get(x + 1))
print(y.value_counts())
p=y.value_counts().plot(kind="bar")

x.shape

y.shape

"""### DATASET STANDARISATION"""

#Standarising the dataset
sc=StandardScaler()
x=sc.fit_transform(x)
x

"""### SPLITING THE DATASET FROM TRAIN TEST PURPOUSE"""

from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.20)

"""### APPLYING THE ALGORITHMS

#### LOGISTIC REGRESSION
"""

from sklearn.linear_model import LogisticRegression
lg=LogisticRegression()
lg.fit(xtrain,ytrain)

lg_pred=lg.predict(xtest)

accuracy_score(ytest,lg_pred)*100

"""#### RANDOM FOREST"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=200)
rfc.fit(xtrain, ytrain)
rfc_pred = rfc.predict(xtest)

from sklearn.metrics import accuracy_score
accuracy_score(ytest,rfc_pred)*100

"""#### GRADIENT BOOSTING"""

# Setting SEED for reproducibility
SEED = 23

# Importing the dataset
X, y = load_digits(return_X_y=True)

# Instantiate Gradient Boosting Regressor
gbc = GradientBoostingClassifier(n_estimators=300,learning_rate=0.05,random_state=100,max_features=5 )
# Fit to training set
gbc.fit(xtrain, ytrain)

# Predict on test set
pred_y = gbc.predict(xtest)

# accuracy
accuracy_score(ytest,pred_y)*100